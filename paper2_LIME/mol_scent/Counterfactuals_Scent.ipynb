{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counterfactual generation using exmol package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Remember to update CUDA_VISIBLE_DEVICES')\n",
    "# For GPU nodes, edit value below based on allocated GPU\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#!pip install matplotlib numpy pandas seaborn jax jaxlib dm-haiku tensorflow exmol\n",
    "import exmol\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.experimental.optimizers as opt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
    "import sklearn.metrics\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\n",
    "    \"dark\",\n",
    "    {\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.color\": \"#666666\",\n",
    "        \"ytick.color\": \"#666666\",\n",
    "        \"axes.edgecolor\": \"#666666\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"figure.dpi\": 300,\n",
    "    },\n",
    ")\n",
    "color_cycle = [\"#1BBC9B\", \"#F06060\", \"#5C4B51\", \"#F3B562\", \"#6e5687\"]\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=color_cycle)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counterfactual Generation with GNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GNN Model Related Code** \n",
    "\n",
    "Code modified from example code given in the \"Predicting DFT Energies with GNNs\" and \"Interpretability and Deep Learning\" sections of \"Deep Learning for Molecules and Materials\" textbook (https://whitead.github.io/dmol-book/applied/QM9.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for GNN model\n",
    "node_feat_length = 256\n",
    "message_feat_length = 256\n",
    "graph_feat_length = 512\n",
    "weights_stddevGNN = 0.01\n",
    "\n",
    "# Code to load data & generate graphs + labels\n",
    "# Load data --> file uploaded to jhub (locally stored)\n",
    "scentdata = pd.read_csv(\"leffingwell_data_shuffled.csv\")\n",
    "\n",
    "# Code to generate list of all scent labels (scentClasses)\n",
    "numMolecules = len(scentdata.odor_labels_filtered)\n",
    "numClasses = 113\n",
    "scentClasses = []\n",
    "moleculeScentList = []\n",
    "for i in range(numMolecules):\n",
    "    scentString = scentdata.odor_labels_filtered[i]\n",
    "    temp = scentString.replace(\"[\", \"\")\n",
    "    temp = temp.replace(\"]\", \"\")\n",
    "    temp = temp.replace(\"'\", \"\")\n",
    "    temp = temp.replace(\" \", \"\")\n",
    "    scentList = temp.split(\",\")\n",
    "    moleculeScentList.append(scentList)\n",
    "    for j in range(len(scentList)):\n",
    "        if not (scentList[j] in scentClasses):\n",
    "            scentClasses.append(scentList[j])\n",
    "\n",
    "# Check to make sure read in data properly & created scentClasses & moleculeScentList correctly\n",
    "print(f\"Is the number of scent classes 113?: {len(scentClasses)==113}\")\n",
    "print(f\"Is the number of molecules 3523?: {len(moleculeScentList)==3523}\")\n",
    "\n",
    "\n",
    "def gen_smiles2graph(sml):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    m = rdkit.Chem.MolFromSmiles(sml)\n",
    "    m = rdkit.Chem.AddHs(m)\n",
    "    order_string = {\n",
    "        rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
    "        rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
    "        rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
    "        rdkit.Chem.rdchem.BondType.AROMATIC: 4,\n",
    "    }\n",
    "    N = len(list(m.GetAtoms()))\n",
    "    nodes = np.zeros((N, node_feat_length))\n",
    "    for i in m.GetAtoms():\n",
    "        nodes[i.GetIdx(), i.GetAtomicNum()] = 1\n",
    "        # Add in whether atom is in a ring or not for one-hot encoding\n",
    "        if i.IsInRing():\n",
    "            nodes[i.GetIdx(), -1] = 1\n",
    "\n",
    "    adj = np.zeros((N, N))\n",
    "    for j in m.GetBonds():\n",
    "        u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        order = j.GetBondType()\n",
    "        if order in order_string:\n",
    "            order = order_string[order]\n",
    "        else:\n",
    "            raise Warning(\"Ignoring bond order\" + order)\n",
    "        adj[u, v] = 1\n",
    "        adj[v, u] = 1\n",
    "    adj += np.eye(N)\n",
    "    return nodes, adj\n",
    "\n",
    "\n",
    "# Function that creates label vector given list of strings describing scent of molecule as input\n",
    "# Each index in label vector corresponds to specific scent -> if output has a 0 at index i, then molecule does not have scent i\n",
    "# If label vector has 1 at index i, then molecule does have scent i\n",
    "def createLabelVector(scentsList):\n",
    "    # Find class index in label vector that each scent corresponds to & update label for that molecule to 1\n",
    "    labelVector = np.zeros(numClasses)\n",
    "    for j in range(len(scentsList)):\n",
    "        # Find class index\n",
    "        classIndex = scentClasses.index(scentsList[j])\n",
    "        # print(classIndex)\n",
    "        # print(scentsList[j])\n",
    "        # print(scentClasses[classIndex])\n",
    "        # Update label vector\n",
    "        labelVector[classIndex] = 1\n",
    "    return labelVector\n",
    "\n",
    "\n",
    "def generateGraphs():\n",
    "    for i in range(numMolecules):\n",
    "        graph = gen_smiles2graph(scentdata.smiles[i])\n",
    "        labels = createLabelVector(moleculeScentList[i])\n",
    "        yield graph, labels\n",
    "\n",
    "\n",
    "# Check that generateGraphs() works for 1st molecule\n",
    "# print(gen_smiles2graph(scentdata.SMILES[0]))\n",
    "# print(scentdata.SENTENCE[0].split(','))\n",
    "# print(np.nonzero(createLabelVector(scentdata.SENTENCE[0].split(','))))\n",
    "# print(scentClasses[89])\n",
    "data = tf.data.Dataset.from_generator(\n",
    "    generateGraphs,\n",
    "    output_types=((tf.float32, tf.float32), tf.float32),\n",
    "    output_shapes=(\n",
    "        (tf.TensorShape([None, node_feat_length]), tf.TensorShape([None, None])),\n",
    "        tf.TensorShape([None]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(\n",
    "    hk.Module\n",
    "):  # TODO: If increase number of layers, stack features & new_features and shrink via dense layer\n",
    "    def __init__(self, output_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # split input into nodes, edges & features\n",
    "        nodes, edges, features = inputs\n",
    "        # Nodes is of shape (N, Nf) --> N = # atoms, Nf = node_feature_length\n",
    "        # Edges is of shape (N,N) (adjacency matrix)\n",
    "        # Features is of shape (Gf) --> Gf = graph_feature_length\n",
    "\n",
    "        graph_feature_len = features.shape[-1]  # graph_feature_len (Gf)\n",
    "        node_feature_len = nodes.shape[-1]  # node_feature_len (Nf)\n",
    "        message_feature_len = message_feat_length  # message_feature_length (Mf)\n",
    "\n",
    "        # Initialize weights\n",
    "        w_init = hk.initializers.RandomNormal(stddev=weights_stddevGNN)\n",
    "\n",
    "        # we is of shape (Nf,Mf)\n",
    "        we = hk.get_parameter(\n",
    "            \"we\", shape=[node_feature_len, message_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # b is of shape (Mf)\n",
    "        b = hk.get_parameter(\"b\", shape=[message_feature_len], init=w_init)\n",
    "\n",
    "        # wv is of shape (Mf,Nf)\n",
    "        wv = hk.get_parameter(\n",
    "            \"wv\", shape=[message_feature_len, node_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # wu is of shape (Nf,Gf)\n",
    "        wu = hk.get_parameter(\n",
    "            \"wu\", shape=[node_feature_len, graph_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # make nodes be N x N x Nf so we can just multiply directly (N = number of atoms)\n",
    "        # ek is now shaped N x N x Mf\n",
    "        ek = jax.nn.leaky_relu(\n",
    "            b\n",
    "            + jnp.repeat(nodes[jnp.newaxis, ...], nodes.shape[0], axis=0)\n",
    "            @ we\n",
    "            * edges[..., None]\n",
    "        )\n",
    "\n",
    "        # Uncomment lines below to update edges\n",
    "        # Update edges, use jnp.any to have new_edges be of shape N x N\n",
    "        # new_edges = jnp.any(ek, axis=-1)\n",
    "\n",
    "        # Normalize over edge features w/layer normalization\n",
    "        # new_edges = hk.LayerNorm(axis=[0,1], create_scale=False, create_offset=False, eps=1e-05)(new_edges)\n",
    "\n",
    "        # take sum over neighbors to get ebar shape = Nf x Mf\n",
    "        ebar = jnp.sum(ek, axis=1)\n",
    "\n",
    "        # dense layer for new nodes to get new_nodes shape = N x Nf\n",
    "        new_nodes = jax.nn.leaky_relu(ebar @ wv) + nodes  # Use leaky ReLU\n",
    "\n",
    "        # Normalize over node features w/layer normalization\n",
    "        new_nodes = hk.LayerNorm(\n",
    "            axis=[0, 1], create_scale=False, create_offset=False, eps=1e-05\n",
    "        )(new_nodes)\n",
    "\n",
    "        # sum over nodes to get shape features so global_node_features shape = Nf\n",
    "        global_node_features = jnp.sum(new_nodes, axis=0)\n",
    "\n",
    "        # dense layer for new features so new_features shape = Gf\n",
    "        new_features = (\n",
    "            jax.nn.leaky_relu(global_node_features @ wu) + features\n",
    "        )  # Use leaky ReLU for activation\n",
    "\n",
    "        return new_nodes, edges, new_features\n",
    "\n",
    "\n",
    "def model_fn(x):\n",
    "    nodes, edges = x\n",
    "    features = jnp.ones(graph_feat_length)\n",
    "    x = nodes, edges, features\n",
    "\n",
    "    # NOTE: If edited config.num_GNN_layers, need to edit code below (increase or decrease # times have x = GNNLayer(...))\n",
    "    # 4 GNN layers\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "\n",
    "    # 2 dense layers\n",
    "    logits = hk.Linear(numClasses)(x[-1])\n",
    "    # logits = jax.nn.relu(logits) #ReLU activation between dense layer\n",
    "    logits = hk.Linear(numClasses)(logits)\n",
    "\n",
    "    return logits  # Model now returns logits\n",
    "\n",
    "\n",
    "model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "# Initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "sampleData = data.take(1)\n",
    "for dataVal in sampleData:  # Look into later how to get larger set\n",
    "    (nodes_i, edges_i), yi = dataVal\n",
    "nodes_i = nodes_i.numpy()\n",
    "edges_i = edges_i.numpy()\n",
    "\n",
    "yi = yi.numpy()\n",
    "xi = (nodes_i, edges_i)\n",
    "\n",
    "params = model.init(rng, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load optimal parameters for GNN model (stored locally)\n",
    "print(\"Edit fileName to change parameters being loaded\")\n",
    "fileName = \"optParams_100Epochs_astral-pond-171.npy\"  # Currently optimal parameters, edit when get better model\n",
    "paramsArr = jnp.load(fileName, allow_pickle=True)\n",
    "opt_params = {\n",
    "    \"gnn_layer\": {\n",
    "        \"b\": paramsArr[0],\n",
    "        \"we\": paramsArr[1],\n",
    "        \"wu\": paramsArr[2],\n",
    "        \"wv\": paramsArr[3],\n",
    "    },\n",
    "    \"gnn_layer_1\": {\n",
    "        \"b\": paramsArr[4],\n",
    "        \"we\": paramsArr[5],\n",
    "        \"wu\": paramsArr[6],\n",
    "        \"wv\": paramsArr[7],\n",
    "    },\n",
    "    \"gnn_layer_2\": {\n",
    "        \"b\": paramsArr[8],\n",
    "        \"we\": paramsArr[9],\n",
    "        \"wu\": paramsArr[10],\n",
    "        \"wv\": paramsArr[11],\n",
    "    },\n",
    "    \"gnn_layer_3\": {\n",
    "        \"b\": paramsArr[12],\n",
    "        \"we\": paramsArr[13],\n",
    "        \"wu\": paramsArr[14],\n",
    "        \"wv\": paramsArr[15],\n",
    "    },\n",
    "    \"linear\": {\"b\": paramsArr[16], \"w\": paramsArr[17]},\n",
    "    \"linear_1\": {\"b\": paramsArr[18], \"w\": paramsArr[19]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in threshold values for each scent class (in test set) that maximizes F1 score\n",
    "thresholds = pd.read_csv(\"ThresholdsForMaxF1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counterfactual Generation Code using exmol package**\n",
    "\n",
    "Code using exmol package modified based on that given in exmol documentation (https://ur-whitelab.github.io/exmol/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model function that takes in SMILES string and scent string as input (rather than molecular graph + parameter)\n",
    "# Output is prediction on whether molecule has a certain scent (1) or not (0)\n",
    "def my_model(smilesString, scentString):\n",
    "    molecularGraph = gen_smiles2graph(smilesString)\n",
    "    pos = scentClasses.index(scentString)\n",
    "    thresholdIndex_scent = thresholds.index[thresholds.Scent == scentString].tolist()\n",
    "    threshold = thresholds.Threshold[thresholdIndex_scent].tolist()[\n",
    "        0\n",
    "    ]  # Threshold is the one that maximizes the F1 score\n",
    "    pred = jax.nn.sigmoid(model.apply(opt_params, molecularGraph))[pos]\n",
    "    if pred > threshold:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If saving counterfactuals or sample space generated to csv, use createExampleListfromDataFrame when plotting/using exmol functions\n",
    "\n",
    "# Need to convert pandas dataframe (created after reading in csv) to a list of Example (Examples definition: https://github.com/ur-whitelab/exmol/blob/main/exmol/data.py)\n",
    "def createExampleListfromDataFrame(data):\n",
    "    exampleList = list[exmol.Example]()\n",
    "    for i in range(len(data.index)):\n",
    "        exampleList.append(\n",
    "            exmol.Example(\n",
    "                data.smiles.tolist()[i],\n",
    "                data.selfies.tolist()[i],\n",
    "                data.similarity.tolist()[i],\n",
    "                data.yhat.tolist()[i],\n",
    "                data.index.tolist()[i],\n",
    "                data.position.tolist()[i],\n",
    "                data.is_origin.tolist()[i],\n",
    "                data.cluster.tolist()[i],\n",
    "                data.label.tolist()[i],\n",
    "            )\n",
    "        )\n",
    "    return exampleList\n",
    "\n",
    "\n",
    "# Uncomment lines below for plotting counterfactuals from csv files saved\n",
    "# cfs1 = createExampleListfromDataFrame(pd.read_csv('cfs1_green.csv'))\n",
    "# exmol.plot_cf(cfs1, nrows=1)\n",
    "# plt.savefig('cfs1_green.png') #Save image of counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMILES Strings for molecules that have \"interesting\" scents/structure-scent relations\n",
    "vanillin = \"COc1cc(C=O)ccc1O\"  # Vanillin smiles string (https://www.sigmaaldrich.com/US/en/product/SIGMA/V2375)\n",
    "isovanillin = \"COc1ccc(C=O)cc1O\"  # Isovanillin smiles string (https://www.sigmaaldrich.com/US/en/product/aldrich/59940)\n",
    "\n",
    "muscone = \"CC1CCCCCCCCCCCCC(=O)C1\"  # Muscone smiles string (https://pubchem.ncbi.nlm.nih.gov/compound/3-Methylcyclopentadecanone#section=InChI-Key)\n",
    "muskKetone = \"CC1=C(C(=C(C(=C1[N+](=O)[O-])C(C)(C)C)[N+](=O)[O-])C)C(=O)C\"  # Musk ketone smiles string (https://pubchem.ncbi.nlm.nih.gov/compound/Musk-ketone#section=InChI)\n",
    "\n",
    "methylAnthranilate = \"COC(=O)C1=CC=CC=C1N\"  # Methyl anthranilate smiles string (grape scent) (https://pubchem.ncbi.nlm.nih.gov/compound/Methyl-anthranilate#section=InChI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scentClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_examples(cond, examples, nmols):\n",
    "    result = []\n",
    "\n",
    "    # similarity filtered by if cluster/counter\n",
    "    def cluster_score(e, i):\n",
    "        return (e.cluster == i) * cond(e) * e.similarity\n",
    "\n",
    "    clusters = set([e.cluster for e in examples])\n",
    "    for i in clusters:\n",
    "        close_counter = max(examples, key=lambda e, i=i: cluster_score(e, i))\n",
    "        # check if actually is (since call could have been zero)\n",
    "        if cluster_score(close_counter, i):\n",
    "            result.append(close_counter)\n",
    "\n",
    "    # trim, in case we had too many cluster\n",
    "    result = sorted(result, key=lambda v: v.similarity * cond(v), reverse=True)[:nmols]\n",
    "\n",
    "    # fill in remaining\n",
    "    ncount = sum([cond(e) for e in result])\n",
    "    fill = max(0, nmols - ncount)\n",
    "    result.extend(\n",
    "        sorted(examples, key=lambda v: v.similarity * cond(v), reverse=True)[:fill]\n",
    "    )\n",
    "\n",
    "    return list(filter(cond, result))\n",
    "\n",
    "\n",
    "def cf_explain(examples, nmols):\n",
    "    \"\"\"From given :obj:`Examples<Example>`, find closest counterfactuals (see :doc:`index`)\n",
    "    :param examples: Output from :func:`sample_space`\n",
    "    :param nmols: Desired number of molecules\n",
    "    \"\"\"\n",
    "\n",
    "    def is_counter(e):\n",
    "        return e.yhat != examples[0].yhat\n",
    "\n",
    "    scent_classes = np.array([x for x in scentClasses])\n",
    "    origin_labels = np.array(\n",
    "        [my_model(examples[0].smiles, scent) for scent in scent_classes]\n",
    "    )\n",
    "    print(origin_labels)\n",
    "    #     print([scentClasses[i] for i, x in enumerate(origin_labels) if x==1])\n",
    "    print(scent_classes[origin_labels == 1])\n",
    "\n",
    "    selection = _select_examples(is_counter, examples[1:], len(examples[1:]))\n",
    "    selection = sorted(\n",
    "        selection, key=lambda v: v.similarity * is_counter(v), reverse=True\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for e in selection:\n",
    "        labels = np.array([my_model(e.smiles, scent) for scent in scent_classes])\n",
    "        flips = origin_labels != labels\n",
    "        print(f\"flipped labels: {scent_classes[flips]}\")\n",
    "        flip_count = np.sum(flips)\n",
    "        if flip_count < 2 and e.similarity > 0.3:\n",
    "            result.append(e)\n",
    "        if len(result) == nmols:\n",
    "            break\n",
    "\n",
    "    for i, r in enumerate(result):\n",
    "        r.label = f\"Counterfactual {i+1}\"\n",
    "\n",
    "    return examples[:1] + result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanillin counterfactuals ('vanilla scent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_vanillin = pd.read_csv(\"samples_vanillin.csv\")\n",
    "samples_vanillin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExampleListfromDataFrame(data):\n",
    "    exampleList = []  # list[exmol.Example]()\n",
    "    for i in range(len(data.index)):\n",
    "        exampleList.append(\n",
    "            exmol.Example(\n",
    "                data.smiles.tolist()[i],\n",
    "                data.selfies.tolist()[i],\n",
    "                data.similarity.tolist()[i],\n",
    "                data.yhat.tolist()[i],\n",
    "                data.index.tolist()[i],\n",
    "                data.position.tolist()[i],\n",
    "                data.is_origin.tolist()[i],\n",
    "                data.cluster.tolist()[i],\n",
    "                data.label.tolist()[i],\n",
    "            )\n",
    "        )\n",
    "    return exampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_vanillin = createExampleListfromDataFrame(samples_vanillin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate vanillin counterfactuals\n",
    "samples_vanillin = exmol.sample_space(\n",
    "    vanillin,\n",
    "    lambda smi, sel: my_model(smi, \"vanilla\"),\n",
    "    batched=False,\n",
    "    preset=\"medium\",\n",
    "    num_samples=50000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfs_vanillin = cf_explain(samples_vanillin, nmols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample space with vanillin as base molecule\n",
    "# exmol.plot_space(samples_vanillin, cfs_vanillin)\n",
    "# plt.savefig('sampleSpace_vanillin.png')\n",
    "\n",
    "# Uncomment lines below to save results to csv\n",
    "cfs_vanillin_data = pd.DataFrame(cfs_vanillin)\n",
    "cfs_vanillin_data.to_csv(\"cfs_vanillin.csv\", index=False)\n",
    "samples_vanillin_data = pd.DataFrame(samples_vanillin)\n",
    "samples_vanillin_data.to_csv(\"samples_vanillin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_vanillin_data = pd.DataFrame(cfs_vanillin)\n",
    "cfs_vanillin_data.to_csv(\"cfs_vanillin.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.plot_cf(cfs_vanillin[:6], nrows=2)  # , nrows=3)\n",
    "plt.savefig(\"cfs_vanillin_truncated.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methyl anthranilate ('grape' scent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Methyl anthranilate\n",
    "# Generate methyl anthranilate counterfactuals\n",
    "samples_methylAnthranilate = exmol.sample_space(\n",
    "    methylAnthranilate,\n",
    "    lambda smi, sel: my_model(smi, \"grape\"),\n",
    "    batched=False,\n",
    "    preset=\"medium\",\n",
    "    num_samples=50000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_methylAnthranilate = pd.read_csv(\"samples_methylAnthranilate.csv\")\n",
    "samples_methylAnthranilate = createExampleListfromDataFrame(samples_methylAnthranilate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot methyl anthranilate counterfactuals\n",
    "cfs_methylAnthranilate = cf_explain(samples_methylAnthranilate, nmols=10)\n",
    "print(f\"Methyl anthranilate Counterfactuals: \")\n",
    "exmol.plot_cf(cfs_methylAnthranilate, nrows=3)\n",
    "plt.savefig(\"cfs_methylAnthranilate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment lines below to save results to csv\n",
    "cfs_methylAnthranilate_data = pd.DataFrame(cfs_methylAnthranilate)\n",
    "cfs_methylAnthranilate_data.to_csv(\"cfs_methylAnthranilate.csv\", index=False)\n",
    "samples_methylAnthranilate_data = pd.DataFrame(samples_methylAnthranilate)\n",
    "samples_methylAnthranilate_data.to_csv(\"samples_methylAnthranilate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_methylAnthranilate_data = pd.DataFrame(cfs_methylAnthranilate)\n",
    "cfs_methylAnthranilate_data.to_csv(\"cfs_methylAnthranilate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.plot_cf(cfs_methylAnthranilate[:6], nrows=2)\n",
    "plt.savefig(\"cfs_methylAnthranilate.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
