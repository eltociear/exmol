{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#!pip install matplotlib numpy pandas seaborn jax jaxlib dm-haiku tensorflow exmol\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "import exmol\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import jax.experimental.optimizers as opt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import haiku as hk\n",
    "import numpy as np\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.rdDepictor, rdkit.Chem.Draw\n",
    "import mordred, mordred.descriptors\n",
    "import sklearn.metrics\n",
    "from IPython.display import display, SVG\n",
    "from rdkit.Chem.Draw import MolToImage as mol2img, DrawMorganBit  # type: ignore\n",
    "from rdkit.Chem import rdchem, MACCSkeys, AllChem  # type: ignore\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\n",
    "    \"dark\",\n",
    "    {\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.color\": \"#666666\",\n",
    "        \"ytick.color\": \"#666666\",\n",
    "        \"axes.edgecolor\": \"#666666\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"figure.dpi\": 300,\n",
    "    },\n",
    ")\n",
    "color_cycle = [\"#1BBC9B\", \"#F06060\", \"#5C4B51\", \"#F3B562\", \"#6e5687\"]\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=color_cycle)\n",
    "mpl.rcParams[\"font.size\"] = 10\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN Model Related Code\n",
    "\n",
    "GNN model using molecular scent dataset from Leffingwell Odor Datset (https://zenodo.org/record/4085098#.YTfYwy1h29Y)\n",
    "\n",
    "Code below modified from example code given in the \"Predicting DFT Energies with GNNs\" and \"Interpretability and Deep Learning\" sections of \"Deep Learning for Molecules and Materials\" textbook (https://whitead.github.io/dmol-book/applied/QM9.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for GNN model\n",
    "node_feat_length = 256\n",
    "message_feat_length = 256\n",
    "graph_feat_length = 512\n",
    "weights_stddevGNN = 0.01\n",
    "\n",
    "\n",
    "# Code to load data & generate graphs + labels for all molecules in dataset\n",
    "# Load data --> file uploaded to jhub (locally stored)\n",
    "scentdata = pd.read_csv(\"leffingwell_data_shuffled.csv\")\n",
    "\n",
    "# Code to generate list of all scent labels (scentClasses)\n",
    "numMolecules = len(scentdata.odor_labels_filtered)\n",
    "numClasses = 112  # No odorless class\n",
    "scentClasses = []\n",
    "moleculeScentList = []\n",
    "for i in range(numMolecules):\n",
    "    scentString = scentdata.odor_labels_filtered[i]\n",
    "    temp = scentString.replace(\"[\", \"\")\n",
    "    temp = temp.replace(\"]\", \"\")\n",
    "    temp = temp.replace(\"'\", \"\")\n",
    "    temp = temp.replace(\" \", \"\")\n",
    "    scentList = temp.split(\",\")\n",
    "    if \"odorless\" in scentList:\n",
    "        scentList.remove(\"odorless\")\n",
    "    moleculeScentList.append(scentList)\n",
    "    for j in range(len(scentList)):\n",
    "        if not (scentList[j] in scentClasses):\n",
    "            scentClasses.append(scentList[j])\n",
    "\n",
    "# Check to make sure read in data properly & created scentClasses & moleculeScentList correctly\n",
    "print(f\"Is the number of scent classes 112?: {len(scentClasses)==112}\")\n",
    "print(f\"Is the number of molecules 3523?: {len(moleculeScentList)==3523}\")\n",
    "\n",
    "\n",
    "def gen_smiles2graph(sml):\n",
    "    \"\"\"Argument for the RD2NX function should be a valid SMILES sequence\n",
    "    returns: the graph\n",
    "    \"\"\"\n",
    "    m = rdkit.Chem.MolFromSmiles(sml)\n",
    "    m = rdkit.Chem.AddHs(m)\n",
    "    order_string = {\n",
    "        rdkit.Chem.rdchem.BondType.SINGLE: 1,\n",
    "        rdkit.Chem.rdchem.BondType.DOUBLE: 2,\n",
    "        rdkit.Chem.rdchem.BondType.TRIPLE: 3,\n",
    "        rdkit.Chem.rdchem.BondType.AROMATIC: 4,\n",
    "    }\n",
    "    N = len(list(m.GetAtoms()))\n",
    "    nodes = np.zeros((N, node_feat_length))\n",
    "    for i in m.GetAtoms():\n",
    "        nodes[i.GetIdx(), i.GetAtomicNum()] = 1\n",
    "        # Add in whether atom is in a ring or not for one-hot encoding\n",
    "        if i.IsInRing():\n",
    "            nodes[i.GetIdx(), -1] = 1\n",
    "\n",
    "    adj = np.zeros((N, N))\n",
    "    for j in m.GetBonds():\n",
    "        u = min(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        v = max(j.GetBeginAtomIdx(), j.GetEndAtomIdx())\n",
    "        order = j.GetBondType()\n",
    "        if order in order_string:\n",
    "            order = order_string[order]\n",
    "        else:\n",
    "            raise Warning(\"Ignoring bond order\" + order)\n",
    "        adj[u, v] = 1\n",
    "        adj[v, u] = 1\n",
    "    adj += np.eye(N)\n",
    "    return nodes, adj\n",
    "\n",
    "\n",
    "# Function that creates label vector given list of strings describing scent of molecule as input\n",
    "# Each index in label vector corresponds to specific scent -> if output has a 0 at index i, then molecule does not have scent i\n",
    "# If label vector has 1 at index i, then molecule does have scent i\n",
    "\n",
    "\n",
    "def createLabelVector(scentsList):\n",
    "    # Find class index in label vector that each scent corresponds to & update label for that molecule to 1\n",
    "    labelVector = np.zeros(numClasses)\n",
    "    for j in range(len(scentsList)):\n",
    "        # Find class index\n",
    "        classIndex = scentClasses.index(scentsList[j])\n",
    "        # print(classIndex)\n",
    "        # print(scentsList[j])\n",
    "        # print(scentClasses[classIndex])\n",
    "        # Update label vector\n",
    "        labelVector[classIndex] = 1\n",
    "    return labelVector\n",
    "\n",
    "\n",
    "def generateGraphs():\n",
    "    for i in range(numMolecules):\n",
    "        graph = gen_smiles2graph(scentdata.smiles[i])\n",
    "        labels = createLabelVector(moleculeScentList[i])\n",
    "        yield graph, labels\n",
    "\n",
    "\n",
    "# Check that generateGraphs() works for 1st molecule\n",
    "# print(gen_smiles2graph(scentdata.SMILES[0]))\n",
    "# print(scentdata.SENTENCE[0].split(','))\n",
    "# print(np.nonzero(createLabelVector(scentdata.SENTENCE[0].split(','))))\n",
    "# print(scentClasses[89])\n",
    "data = tf.data.Dataset.from_generator(\n",
    "    generateGraphs,\n",
    "    output_types=((tf.float32, tf.float32), tf.float32),\n",
    "    output_shapes=(\n",
    "        (tf.TensorShape([None, node_feat_length]), tf.TensorShape([None, None])),\n",
    "        tf.TensorShape([None]),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(\n",
    "    hk.Module\n",
    "):  # TODO: If increase number of layers, stack features & new_features and shrink via dense layer\n",
    "    def __init__(self, output_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        # split input into nodes, edges & features\n",
    "        nodes, edges, features = inputs\n",
    "        # Nodes is of shape (N, Nf) --> N = # atoms, Nf = node_feature_length\n",
    "        # Edges is of shape (N,N) (adjacency matrix)\n",
    "        # Features is of shape (Gf) --> Gf = graph_feature_length\n",
    "\n",
    "        graph_feature_len = features.shape[-1]  # graph_feature_len (Gf)\n",
    "        node_feature_len = nodes.shape[-1]  # node_feature_len (Nf)\n",
    "        message_feature_len = message_feat_length  # message_feature_length (Mf)\n",
    "\n",
    "        # Initialize weights\n",
    "        w_init = hk.initializers.RandomNormal(stddev=weights_stddevGNN)\n",
    "\n",
    "        # we is of shape (Nf,Mf)\n",
    "        we = hk.get_parameter(\n",
    "            \"we\", shape=[node_feature_len, message_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # b is of shape (Mf)\n",
    "        b = hk.get_parameter(\"b\", shape=[message_feature_len], init=w_init)\n",
    "\n",
    "        # wv is of shape (Mf,Nf)\n",
    "        wv = hk.get_parameter(\n",
    "            \"wv\", shape=[message_feature_len, node_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # wu is of shape (Nf,Gf)\n",
    "        wu = hk.get_parameter(\n",
    "            \"wu\", shape=[node_feature_len, graph_feature_len], init=w_init\n",
    "        )\n",
    "\n",
    "        # make nodes be N x N x Nf so we can just multiply directly (N = number of atoms)\n",
    "        # ek is now shaped N x N x Mf\n",
    "        ek = jax.nn.leaky_relu(\n",
    "            b\n",
    "            + jnp.repeat(nodes[jnp.newaxis, ...], nodes.shape[0], axis=0)\n",
    "            @ we\n",
    "            * edges[..., None]\n",
    "        )\n",
    "\n",
    "        # Uncomment lines below to update edges\n",
    "        # Update edges, use jnp.any to have new_edges be of shape N x N\n",
    "        # new_edges = jnp.any(ek, axis=-1)\n",
    "\n",
    "        # Normalize over edge features w/layer normalization\n",
    "        # new_edges = hk.LayerNorm(axis=[0,1], create_scale=False, create_offset=False, eps=1e-05)(new_edges)\n",
    "\n",
    "        # take sum over neighbors to get ebar shape = Nf x Mf\n",
    "        ebar = jnp.sum(ek, axis=1)\n",
    "\n",
    "        # dense layer for new nodes to get new_nodes shape = N x Nf\n",
    "        new_nodes = jax.nn.leaky_relu(ebar @ wv) + nodes  # Use leaky ReLU\n",
    "\n",
    "        # Normalize over node features w/layer normalization\n",
    "        new_nodes = hk.LayerNorm(\n",
    "            axis=[0, 1], create_scale=False, create_offset=False, eps=1e-05\n",
    "        )(new_nodes)\n",
    "\n",
    "        # sum over nodes to get shape features so global_node_features shape = Nf\n",
    "        global_node_features = jnp.sum(new_nodes, axis=0)\n",
    "\n",
    "        # dense layer for new features so new_features shape = Gf\n",
    "        new_features = (\n",
    "            jax.nn.leaky_relu(global_node_features @ wu) + features\n",
    "        )  # Use leaky ReLU for activation\n",
    "\n",
    "        return new_nodes, edges, new_features\n",
    "\n",
    "\n",
    "def model_fn(x):\n",
    "    nodes, edges = x\n",
    "    features = jnp.ones(graph_feat_length)\n",
    "    x = nodes, edges, features\n",
    "\n",
    "    # NOTE: If edited config.num_GNN_layers, need to edit code below (increase or decrease # times have x = GNNLayer(...))\n",
    "    # 4 GNN layers\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "    x = GNNLayer(output_size=graph_feat_length)(x)\n",
    "\n",
    "    # 2 dense layers\n",
    "    logits = hk.Linear(numClasses)(x[-1])\n",
    "    # logits = jax.nn.relu(logits) #ReLU activation between dense layer\n",
    "    logits = hk.Linear(numClasses)(logits)\n",
    "\n",
    "    return logits  # Model now returns logits\n",
    "\n",
    "\n",
    "model = hk.without_apply_rng(hk.transform(model_fn))\n",
    "\n",
    "# Initialize model\n",
    "rng = jax.random.PRNGKey(0)\n",
    "sampleData = data.take(1)\n",
    "for dataVal in sampleData:  # Look into later how to get larger set\n",
    "    (nodes_i, edges_i), yi = dataVal\n",
    "nodes_i = nodes_i.numpy()\n",
    "edges_i = edges_i.numpy()\n",
    "\n",
    "yi = yi.numpy()\n",
    "xi = (nodes_i, edges_i)\n",
    "\n",
    "params = model.init(rng, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimal parameters for GNN model\n",
    "print(\"Edit fileName to change parameters being loaded\")\n",
    "fileName = \"optParams_dry-waterfall-17.npy\"  # Currently optimal parameters, edit when get better model\n",
    "paramsArr = jnp.load(fileName, allow_pickle=True)\n",
    "opt_params = {\n",
    "    \"gnn_layer\": {\n",
    "        \"b\": paramsArr[0],\n",
    "        \"we\": paramsArr[1],\n",
    "        \"wu\": paramsArr[2],\n",
    "        \"wv\": paramsArr[3],\n",
    "    },\n",
    "    \"gnn_layer_1\": {\n",
    "        \"b\": paramsArr[4],\n",
    "        \"we\": paramsArr[5],\n",
    "        \"wu\": paramsArr[6],\n",
    "        \"wv\": paramsArr[7],\n",
    "    },\n",
    "    \"gnn_layer_2\": {\n",
    "        \"b\": paramsArr[8],\n",
    "        \"we\": paramsArr[9],\n",
    "        \"wu\": paramsArr[10],\n",
    "        \"wv\": paramsArr[11],\n",
    "    },\n",
    "    \"gnn_layer_3\": {\n",
    "        \"b\": paramsArr[12],\n",
    "        \"we\": paramsArr[13],\n",
    "        \"wu\": paramsArr[14],\n",
    "        \"wv\": paramsArr[15],\n",
    "    },\n",
    "    \"linear\": {\"b\": paramsArr[16], \"w\": paramsArr[17]},\n",
    "    \"linear_1\": {\"b\": paramsArr[18], \"w\": paramsArr[19]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in threshold values for each scent class (in test set) that maximizes F1 score\n",
    "thresholds = pd.read_csv(\"ThresholdsForMaxF1_OdorlessClassRemoved_dry-waterfall-17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(smilesString, scentString):\n",
    "    molecularGraph = gen_smiles2graph(smilesString)\n",
    "    pos = scentClasses.index(scentString)\n",
    "    thresholdIndex_scent = thresholds.index[thresholds.Scent == scentString].tolist()\n",
    "    threshold = thresholds.Threshold[thresholdIndex_scent].tolist()[\n",
    "        0\n",
    "    ]  # Threshold is the one that maximizes the F1 score\n",
    "    pred = jax.nn.sigmoid(model.apply(opt_params, molecularGraph))[pos]\n",
    "    if pred > threshold:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExampleListfromDataFrame(data):\n",
    "    exampleList = []  # list[exmol.Example]()\n",
    "    for i in range(len(data.index)):\n",
    "        # using weighted tanimoto with dot product\n",
    "        exampleList.append(\n",
    "            exmol.Example(\n",
    "                data.smiles.tolist()[i],\n",
    "                data.selfies.tolist()[i],\n",
    "                data.label_similarity.tolist()[i],\n",
    "                data.yhat.tolist()[i],\n",
    "                data.index.tolist()[i],\n",
    "                data.position.tolist()[i],\n",
    "                data.is_origin.tolist()[i],\n",
    "                data.cluster.tolist()[i],\n",
    "                data.label.tolist()[i],\n",
    "            )\n",
    "        )\n",
    "    return exampleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dot product with labels\n",
    "def cosine_similarity_base(df, bases, llists):\n",
    "    df[\"label_dot\"] = np.array(0.0)\n",
    "    for j, row in df.iterrows():\n",
    "        if j in bases:\n",
    "            base = j\n",
    "            df[\"label_dot\"][j] = 1\n",
    "        else:\n",
    "            # cosine similarity\n",
    "            if np.all(llists[j] == 0):\n",
    "                df[\"label_dot\"][j] = 0\n",
    "                continue\n",
    "            df[\"label_dot\"][j] = (\n",
    "                llists[base]\n",
    "                @ llists[j]\n",
    "                / np.linalg.norm(llists[base])\n",
    "                / np.linalg.norm(llists[j])\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df = pd.read_csv(\"spaces_scent/space_vanilla.csv\", usecols=np.arange(1, 11))\n",
    "# vanilla_df['lsimilarity'] = np.array(0.)\n",
    "vanilla_labels = pd.read_csv(\n",
    "    \"spaces_scent/space_vanilla.csv\", usecols=np.append([1], np.arange(11, 123))\n",
    ")\n",
    "llists = vanilla_labels.to_numpy()[:, 1:]\n",
    "bases = list(vanilla_df[vanilla_df[\"is_origin\"] == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df = cosine_similarity_base(vanilla_df, bases, llists)\n",
    "vanilla_df[\"label_similarity\"] = vanilla_df[\"similarity\"] * vanilla_df[\"label_dot\"]\n",
    "plt.plot(vanilla_df[\"similarity\"], vanilla_df[\"label_similarity\"], \".\", alpha=0.7)\n",
    "plt.plot(vanilla_df[\"similarity\"], vanilla_df[\"similarity\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_df.to_csv(\"vanilla_samples_label_weighted_similarity.csv\")\n",
    "vanilla_samples = createExampleListfromDataFrame(vanilla_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptor Explanation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"MACCS\")\n",
    "exmol.plot_descriptors(vanilla_samples, output_file=\"vanilla_maccs.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla_samples[1].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"ECFP\")\n",
    "svg = exmol.plot_descriptors(\n",
    "    vanilla_samples, output_file=\"ecfp_vanilla_scent.svg\", return_svg=True\n",
    ")\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "display(SVG(svg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla_samples[0].descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language explanation prompts where lime_explain is called separately for maccs & ecfp descriptors and then the top k descriptors are given in the prompt (method 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exmol.text_explain2_maccs_and_ecfp(vanilla_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with different maximum number of descriptors in prompt\n",
    "print(exmol.text_explain2_maccs_and_ecfp(vanilla_samples, num_descriptors=5))\n",
    "print(exmol.text_explain2_maccs_and_ecfp(vanilla_samples, num_descriptors=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural language explanation prompts where for the \"combined\" descriptor type, the lime_explain is called on a combination of maccs & ecfp descriptors (method 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    exmol.text_explain(vanilla_samples)\n",
    "    + \"Explanation: Molecules have vanilla smell because\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla_samples[0].descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"ecfp\")\n",
    "prompt = (\n",
    "    exmol.text_explain(vanilla_samples)\n",
    "    + \"Explanation: Molecules have vanilla smell because\"\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional tests & code\n",
    "(Includes code used to identify why 'alkyl aryl ether' was not appearing as a descriptor in the natural language explanations using exmol.text_explain with only 'ECFP' (not combined) and code to test exmol.text_explain2_maccs_and_ecfp() function/make sure all descriptors corresponded to a base molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first base molecule to see where 'Vinylogous ester' may be coming from (the 2nd & 3rd descriptors in the ECFP plot are 'aklyl aryl ether' not esters)\n",
    "# Use code sent by Prof. White on slack for naming\n",
    "def load_smarts(path):\n",
    "    smarts = []\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \"#\":\n",
    "                continue\n",
    "            i = line.find(\":\")\n",
    "            sm = line[i + 1 :].strip()\n",
    "            m = rdkit.Chem.MolFromSmarts(sm)\n",
    "            smarts.append((line[:i].strip(), m))\n",
    "    return smarts[::-1]\n",
    "\n",
    "\n",
    "smarts = load_smarts(\n",
    "    \"/scratch/aseshad4/ScentPredictionNewSplits/OdorlessRemoved/SpaceGenerationAndExplanations/exmol/exmol/lime_data/smarts.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def name(m, smarts=smarts):\n",
    "    names = []\n",
    "    for name, sm in smarts:\n",
    "        match = m.GetSubstructMatches(sm)\n",
    "        if match:\n",
    "            names.append((len(match), name))\n",
    "    names.sort()\n",
    "    return names[-1][1].replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "print(name(rdkit.Chem.MolFromSmiles(\"CC/C(C=O)=C\\C1=CC=CO1\")))\n",
    "rdkit.Chem.MolFromSmiles(\"CC/C(C=O)=C\\C1=CC=CO1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noticed in exmol.py code for text explanation function, descriptors were only added to d_importance dictionary if examples[0].descriptors.descriptors[i] !=0\n",
    "##Cells below test to see whether there is a case where examples[0].descriptors.descriptors[i] ==0 but for a different base molecule, it does not equal 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code needed to name ECFP fingerprints with multiple bases (from exmol.py file)\n",
    "_SMARTS = None\n",
    "\n",
    "\n",
    "def _bit2atoms(m, bitInfo, key):\n",
    "    # get atom id and radius\n",
    "    i, r = bitInfo[key][0]  # just take first matching atom\n",
    "    # taken from rdkit drawing code\n",
    "    bitPath = rdkit.Chem.FindAtomEnvironmentOfRadiusN(m, r, i)\n",
    "\n",
    "    # get the atoms for highlighting\n",
    "    atoms = set((i,))\n",
    "    for b in bitPath:\n",
    "        atoms.add(m.GetBondWithIdx(b).GetBeginAtomIdx())\n",
    "        atoms.add(m.GetBondWithIdx(b).GetEndAtomIdx())\n",
    "    return atoms\n",
    "\n",
    "\n",
    "def _load_smarts(path):\n",
    "    smarts = []\n",
    "    with open(path) as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == \"#\":\n",
    "                continue\n",
    "            i = line.find(\":\")\n",
    "            sm = line[i + 1 :].strip()\n",
    "            m = rdkit.Chem.MolFromSmarts(sm)\n",
    "            smarts.append((line[:i].strip(), m))\n",
    "    return smarts[::-1]\n",
    "\n",
    "\n",
    "def _name_morgan_bit(m, bitInfo, key):\n",
    "    global _SMARTS\n",
    "    if _SMARTS is None:\n",
    "        from importlib_resources import files  # type: ignore\n",
    "        import exmol.lime_data  # type: ignore\n",
    "\n",
    "        sp = files(exmol.lime_data).joinpath(\"smarts.txt\")\n",
    "        _SMARTS = _load_smarts(sp)\n",
    "    morgan_atoms = _bit2atoms(m, bitInfo, key)\n",
    "    if len(morgan_atoms) == 1:\n",
    "        # only 1 atom, just return element\n",
    "        return m.GetAtomWithIdx(list(morgan_atoms)[0]).GetSymbol()\n",
    "    names = []\n",
    "    for name, sm in _SMARTS:\n",
    "        matches = m.GetSubstructMatches(sm)\n",
    "        for match in matches:\n",
    "            # check if match is in morgan bit\n",
    "            match = set(match)\n",
    "            if match.issubset(morgan_atoms):\n",
    "                names.append((len(match), name))\n",
    "    names.sort()\n",
    "    if len(names) == 0:\n",
    "        return None\n",
    "    return names[-1][1].replace(\"_\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test showing example where vanilla_samples[0].descriptors.descriptors[pos] == 0\n",
    "## but that descriptor is present in one of the other base molecules (just not the first)\n",
    "\n",
    "base_mol = [exmol.smi2mol(e.smiles) for e in vanilla_samples if e.is_origin == True]\n",
    "bi = {}  # type: Dict[Any, Any]\n",
    "for b in base_mol:\n",
    "    bit_info = {}  # type: Dict[Any, Any]\n",
    "    fp = AllChem.GetMorganFingerprint(b, 3, bitInfo=bit_info)\n",
    "    for bit in bit_info:\n",
    "        if bit not in bi:\n",
    "            bi[bit] = (b, bit, bit_info)\n",
    "\n",
    "# Example where vanilla_samples[0].descriptors.descriptors[pos] == 0 but that descriptor is present in one of the base molecules\n",
    "pos = vanilla_samples[0].descriptors.descriptor_names.index(616584597)\n",
    "base_molecules = [e for e in vanilla_samples if e.is_origin == True]\n",
    "base_molecules_descriptor_values = [\n",
    "    base_mol.descriptors.descriptors[pos] for base_mol in base_molecules\n",
    "]\n",
    "print(np.count_nonzero(base_molecules_descriptor_values))\n",
    "print(vanilla_samples[0].descriptors.descriptors[pos])\n",
    "k = vanilla_samples[0].descriptors.descriptor_names[pos]\n",
    "m = bi[int(k)][0]\n",
    "b = bi[int(k)][2]\n",
    "name = _name_morgan_bit(m, b, k)\n",
    "print(f\"Name corresponding to key {k}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that descriptors in d_importance (see exmol.py text_explain functions) are all found in the base molecules (there is at least 1 base molecule with that descriptor)\n",
    "\n",
    "# Code below copied from text_explain2 function in exmol.py file for this test\n",
    "# First get results for MACCS descriptors\n",
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"maccs\")\n",
    "tstats_maccs = list(vanilla_samples[0].descriptors.tstats)\n",
    "\n",
    "# Take t-statistics, rank them\n",
    "d_importance_maccs = {\n",
    "    a: [b, i]\n",
    "    for i, a, b in zip(\n",
    "        np.arange(len(vanilla_samples[0].descriptors.descriptors)),\n",
    "        vanilla_samples[0].descriptors.descriptor_names,\n",
    "        tstats_maccs,\n",
    "    )\n",
    "    if not np.isnan(b) and vanilla_samples[0].descriptors.descriptors[i] != 0\n",
    "}\n",
    "\n",
    "base_molecules = [e for e in vanilla_samples if e.is_origin == True]\n",
    "for i, (k, v) in enumerate(d_importance_maccs.items()):\n",
    "    pos = vanilla_samples[0].descriptors.descriptor_names.index(k)\n",
    "    base_molecules_descriptor_values = [\n",
    "        base_mol.descriptors.descriptors[pos] for base_mol in base_molecules\n",
    "    ]\n",
    "    if (\n",
    "        np.count_nonzero(base_molecules_descriptor_values) == 0\n",
    "    ):  # Found a MACCS descriptor not in the base molecules\n",
    "        print(k)\n",
    "\n",
    "# Then test for ECFP descriptors\n",
    "exmol.lime_explain(vanilla_samples, descriptor_type=\"ecfp\")\n",
    "tstats_ecfp = list(vanilla_samples[0].descriptors.tstats)\n",
    "\n",
    "# Take t-statistics, rank them\n",
    "d_importance_ecfp = {\n",
    "    a: [b, i]\n",
    "    for i, a, b in zip(\n",
    "        np.arange(len(vanilla_samples[0].descriptors.descriptors)),\n",
    "        vanilla_samples[0].descriptors.descriptor_names,\n",
    "        tstats_ecfp,\n",
    "    )\n",
    "    if not np.isnan(b) and vanilla_samples[0].descriptors.descriptors[i] != 0\n",
    "}\n",
    "\n",
    "base_molecules = [e for e in vanilla_samples if e.is_origin == True]\n",
    "for i, (k, v) in enumerate(d_importance_ecfp.items()):\n",
    "    pos = vanilla_samples[0].descriptors.descriptor_names.index(k)\n",
    "    base_molecules_descriptor_values = [\n",
    "        base_mol.descriptors.descriptors[pos] for base_mol in base_molecules\n",
    "    ]\n",
    "    if (\n",
    "        np.count_nonzero(base_molecules_descriptor_values) == 0\n",
    "    ):  # Found an ecfp descriptor not in base molecules\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-rdkit-env)",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
